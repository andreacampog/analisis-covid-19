{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b436b952-cf7a-43c7-8e55-49d34b64d54f",
   "metadata": {},
   "source": [
    "## Pasos iniciales: \n",
    "**1. Importarmos los modulos pandas, numpy, y pyplot**\n",
    "\n",
    "**2. Creamos la variable originalDf asignandole el DataSet**\n",
    "\n",
    "**3. Mostramos los primeros 5 registros del DataFrame**\n",
    "\n",
    "    Con el objetivo de tener un panorama general de entrada podemos observar que\n",
    "    existen valores Nan en Province/State lo que nos permite notar\n",
    "    dos posibles panoramas:\n",
    "\n",
    "    Eliminar las columnas que son inecesarias para responder las preguntas planteadas? o\n",
    "\n",
    "    Transformar estos valores NaN para contar con todos los datos? \n",
    "\n",
    "    Continuaremos la exploración para tomar decisiones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91387f78-afba-48e1-a577-63a80513cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#para manipulacion de formato en español y ultima fecha del archivo\n",
    "import locale \n",
    "import calendar  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2434d965-2279-4135-8f62-63b98afdafd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es_ES.UTF-8'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8') #Para poner el formato de mes en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "692d33eb-60b7-48a4-84b5-71135209847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalDf = pd.read_csv('covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adbe6283-d280-48ed-bf9c-d782976a67b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209322</td>\n",
       "      <td>209340</td>\n",
       "      <td>209358</td>\n",
       "      <td>209362</td>\n",
       "      <td>209369</td>\n",
       "      <td>209390</td>\n",
       "      <td>209406</td>\n",
       "      <td>209436</td>\n",
       "      <td>209451</td>\n",
       "      <td>209451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>334391</td>\n",
       "      <td>334408</td>\n",
       "      <td>334408</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334443</td>\n",
       "      <td>334457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271441</td>\n",
       "      <td>271448</td>\n",
       "      <td>271463</td>\n",
       "      <td>271469</td>\n",
       "      <td>271469</td>\n",
       "      <td>271477</td>\n",
       "      <td>271477</td>\n",
       "      <td>271490</td>\n",
       "      <td>271494</td>\n",
       "      <td>271496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47866</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47890</td>\n",
       "      <td>47890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105255</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105288</td>\n",
       "      <td>105288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
       "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
       "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
       "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
       "3        0        0        0        0  ...    47866   47875   47875   47875   \n",
       "4        0        0        0        0  ...   105255  105277  105277  105277   \n",
       "\n",
       "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0  209369  209390  209406  209436  209451  209451  \n",
       "1  334427  334427  334427  334427  334443  334457  \n",
       "2  271469  271477  271477  271490  271494  271496  \n",
       "3   47875   47875   47875   47875   47890   47890  \n",
       "4  105277  105277  105277  105277  105288  105288  \n",
       "\n",
       "[5 rows x 1147 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d8185-2df6-46ce-b5fb-1596276930ac",
   "metadata": {},
   "source": [
    "**4. Verificamos los registros totales, los registrs nulos de cada columna**\n",
    "\n",
    "    Tenemos 289 registros (filas) y 1147 columnas    \n",
    "    Verificamos tambien con .info() el tipo DataType de cada columna encontrando que:\n",
    "    Province/State y Country/Region son variables categoricas \n",
    "    Lat y Long son variables float64\n",
    "    Y las fechas son númericas (deberian ser Date)\n",
    "\n",
    "    Hasta el momento podremos comentar que las fechas deberían modificarse a tipo Date para lograr una correcta manipulacion de los datos\n",
    "    de cara a responder las preguntas que se han planteado en el proyecto \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe9c637-933b-4baa-9277-604e9d60caea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 1147)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e5bc3d-9706-4548-931c-7514b4cd6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Columns: 1147 entries, Province/State to 3/9/23\n",
      "dtypes: float64(2), int64(1143), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "originalDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af3ead-edda-4888-b1c1-2470a316eaa6",
   "metadata": {},
   "source": [
    "originalDf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d216b-8d51-4821-a8ef-eee290c2069f",
   "metadata": {},
   "source": [
    "**Basados en las preguntas:**\n",
    "\n",
    "1. ¿En cuál mes se presentó el mayor número de contagios?\n",
    "2. ¿En ese mismo mes, cuál fue el país que reportó más contagios?\n",
    "3. ¿Cuál es el país con el menor número de casos reportados hasta la\n",
    "fecha?\n",
    "\n",
    "**5. Analizamos  que:**\n",
    "\n",
    "    -Las columnas **Province/State y Lat y Long** no son de importancia para responder las preguntas planteadas\n",
    "    -Las fechas como evidenciamos antes deben ser llevadas a formato dateTime\n",
    "    -El mes necesita ser separado para el posterior analisis \n",
    "    -Ademas encontramos que el valor de la columna contagios es acumulativo\n",
    "    \n",
    "    Entonces: \n",
    "    \n",
    "    -Eliminamos las columnas **Province/State y Lat y Long**\n",
    "    \n",
    "    -Reorganizamos el DataFrame para convertir las columnas de fechas en una columna única\n",
    "    llamada **Fecha** con formato **datetime** con los valores de **Contagios** en otra    columna\n",
    "    \n",
    "    -Cambiamos el nombre de la columna **Country/Region** a **Pais**\n",
    "    \n",
    "    -Separamos el mes de cada fecha y lo guardamos en una columna mes \n",
    "\n",
    "    -Para resolver el problema de la columna acumulativa vamos a obtener el total de contagios\n",
    "    diarios restando el valor acumulado del dia anterior .diff()\n",
    "    \n",
    "    Para ello usaremos una copia de nuestro DF original en df_toclean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6142be-933a-470d-98fc-20cda617ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toclean = originalDf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c10ff-d461-4daa-b5ac-b1e3ef046bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5d52e7-46e7-4533-8563-d0dca5ae7bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country/Region    0\n",
       "1/22/20           0\n",
       "1/23/20           0\n",
       "1/24/20           0\n",
       "1/25/20           0\n",
       "                 ..\n",
       "3/5/23            0\n",
       "3/6/23            0\n",
       "3/7/23            0\n",
       "3/8/23            0\n",
       "3/9/23            0\n",
       "Length: 1144, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toclean.drop(columns=['Province/State', 'Lat', 'Long'], inplace=True)\n",
    "df_toclean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56202922-6a9a-4003-b4f9-2abf7bf1e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_toclean.melt(id_vars=[\"Country/Region\"], var_name=\"Fecha\", value_name=\"Contagios\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6bf4388-777c-46a7-9496-a9a8ec201a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toclean = df_toclean[~df_toclean['Country/Region'].isin([\"Winter Olympics 2022\", \"Summer Olympics 2020\",'Diamond Princess', 'MS Zaandam'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c4dec-c634-45bc-a180-e244d5e25467",
   "metadata": {},
   "source": [
    "Cambiamos el nombre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "757a50b1-5f30-47be-bb30-b232f3a4f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['Fecha'] = pd.to_datetime(df_melted['Fecha'], format='%m/%d/%y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fbe0d-edf5-4f9a-8590-c915ab6e2b26",
   "metadata": {},
   "source": [
    "Ordenamos los datos por País y Fecha para calcular a diario\n",
    "\n",
    "Calculamos el número de contagios diarios restando el valor acumulado del dia anterior\n",
    "Hacemos uso del metodo .diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189e1f21-f775-4f56-9d48-d8d0a94978aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_melted = df_melted.sort_values(by=['Country/Region', 'Fecha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df7bc941-65d5-495d-a476-2d3b648c9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['ContagiosDiarios'] = df_melted.groupby('Country/Region')['Contagios'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52d89205-780a-49e2-a105-4cc6efef9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted['Mes'] = df_melted['Fecha'].dt.month\n",
    "df_melted['Año'] = df_melted['Fecha'].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5f3c8-984e-4ad6-bec6-3c6266aa7143",
   "metadata": {},
   "source": [
    "**Pensando en que estos registros no representan información de paises**\n",
    "\n",
    "    Eliminamos los  registros \"Winter Olympics 2022\", \"Summer Olympics 2020\" ,'Diamond Princess', 'MS Zaandam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78d3cd86-26bc-41e5-9982-c3a241e5f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted.rename(columns={\"Country/Region\": \"Pais\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f0807-02a7-4c6a-8714-b55500310d5c",
   "metadata": {},
   "source": [
    "**6. Finalmente respondemos las preguntas:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3541d50-ee26-4567-a0eb-ab1604e6a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mes con el mayor número de contagios es: Enero del año 2022, con 87136808.0 contagios.\n"
     ]
    }
   ],
   "source": [
    "contagios_por_mes_año = df_melted.groupby(['Año', 'Mes'])['ContagiosDiarios'].sum()\n",
    "mes_año_max_contagios = contagios_por_mes_año.idxmax()\n",
    "max_contagios = contagios_por_mes_año.max()\n",
    "nombre_mes_max_contagios = calendar.month_name[mes_año_max_contagios[1]].capitalize()\n",
    "\n",
    "print(f\"El mes con el mayor número de contagios es: {nombre_mes_max_contagios} del año {mes_año_max_contagios[0]}, con {max_contagios} contagios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecd99037-7ed4-41ba-aabb-fde5360c2aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En 1/2022, el país con más contagios fue US, con 20336435.0 contagios.\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 2: ¿En ese mismo mes y año, cuál fue el país que reportó más contagios y cuántos fueron?\n",
    "df_mes_año_max = df_melted[(df_melted['Mes'] == mes_año_max_contagios[1]) & (df_melted['Año'] == mes_año_max_contagios[0])]\n",
    "pais_max_contagios = df_mes_año_max.groupby('Pais')['ContagiosDiarios'].sum().idxmax()\n",
    "contagios_pais_max = df_mes_año_max.groupby('Pais')['ContagiosDiarios'].sum().max()\n",
    "print(f\"En {mes_año_max_contagios[1]}/{mes_año_max_contagios[0]}, el país con más contagios fue {pais_max_contagios}, con {contagios_pais_max} contagios.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b396ba75-d03a-4af0-8ba4-b68381782728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El país con el menor número de casos reportados es: Korea, North, con 1.0 contagios.\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 3: ¿Cuál es el país con el menor número de casos reportados hasta la fecha?\n",
    "contagios_totales_por_pais = df_melted.groupby('Pais')['ContagiosDiarios'].sum()\n",
    "pais_min_contagios = contagios_totales_por_pais.idxmin()\n",
    "contagios_pais_min = contagios_totales_por_pais.min()\n",
    "print(f\"El país con el menor número de casos reportados es: {pais_min_contagios}, con {contagios_pais_min} contagios.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14348189-e19f-4935-8c07-9a363d272d10",
   "metadata": {},
   "source": [
    "Verificamos las columnas y que no existan valores null ademas usamos .sample() para visualizar el formato del df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fa470e5-56a7-41f0-a7e2-cf28636b5182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 330327 entries, 0 to 330326\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Pais              330327 non-null  object        \n",
      " 1   Fecha             330327 non-null  datetime64[ns]\n",
      " 2   Contagios         330327 non-null  int64         \n",
      " 3   ContagiosDiarios  330327 non-null  float64       \n",
      " 4   Mes               330327 non-null  int32         \n",
      " 5   Año               330327 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(1), int32(2), int64(1), object(1)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_melted.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27a620d6-bd6f-421f-a105-523d11825a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pais</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Contagios</th>\n",
       "      <th>ContagiosDiarios</th>\n",
       "      <th>Mes</th>\n",
       "      <th>Año</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27455</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>1463</td>\n",
       "      <td>133.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27744</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>1531</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28033</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>1703</td>\n",
       "      <td>172.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28322</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>1827</td>\n",
       "      <td>124.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28611</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>1827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Pais      Fecha  Contagios  ContagiosDiarios  Mes   Año\n",
       "0      Afghanistan 2020-01-22          0               0.0    1  2020\n",
       "289    Afghanistan 2020-01-23          0               0.0    1  2020\n",
       "578    Afghanistan 2020-01-24          0               0.0    1  2020\n",
       "867    Afghanistan 2020-01-25          0               0.0    1  2020\n",
       "1156   Afghanistan 2020-01-26          0               0.0    1  2020\n",
       "...            ...        ...        ...               ...  ...   ...\n",
       "27455  Afghanistan 2020-04-26       1463             133.0    4  2020\n",
       "27744  Afghanistan 2020-04-27       1531              68.0    4  2020\n",
       "28033  Afghanistan 2020-04-28       1703             172.0    4  2020\n",
       "28322  Afghanistan 2020-04-29       1827             124.0    4  2020\n",
       "28611  Afghanistan 2020-04-30       1827               0.0    4  2020\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melted.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ab41d9c-6c57-4b85-a453-c155d6d77008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_melted.to_csv('covid_melted.csv', index=False)\n",
    "#df_melted.to_excel('covid_melted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b9c0c-72ab-4445-9eb6-e8711b351d3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "#### Investigación: \n",
    "**melt()**: Se utiliza para reestructurar datos. Convierte columnas en filas\n",
    "\n",
    "**loc[]**: Se utiliza para acceder a filas y columnas especificas por etiquetas o condiciones\n",
    "\n",
    "**get_level_values()**: Se utiliza para obtener valores especificos en DataFrames con índices  \n",
    "jerárquicos, despues de agrupar valores\n",
    "\n",
    "**max() min()**: Se utilizan para obtener maximo y/o minimo de una columna o DataFrame\n",
    "\n",
    "**drop**:  Eliminar columnas \n",
    "\n",
    "\n",
    "\n",
    "**Conclusión:**\n",
    "En el ambito de la Ciencia de Datos la biblioteca Pandas se ha convertido en una herramienta esencial. Desde su creacion ha facilitado el análisis y la manipulación de datos de formas que antes eran complicadas.\n",
    "\n",
    "Antes de su creacion los cientificos de datos dependian de herramientas menos eficaces como Exel, R y SQL que aunque siendo poderesos requerian mayores esfuerzos comparados con Pandas ademas de hacer del analisis de datos una tarea tediosa, frustrante y muy demandante de tiempo por la limpieza y transformacion de los datos.\n",
    "\n",
    "En 2008 Wes McKinney desarrollo Pandas mientras trabajaba en el análisis de datos en AQR Capital Management. Su objetivo era crear una herramienta que facilitara la manipulación de los datos, en su caso especialmente financieros, Pandas ha venido evolucionando constantemente desde aquel dia, introduccion de estructuras como series y DataFrames, compatibilidad con datos mas complejos y rendimiento.\n",
    "\n",
    "Entre los beneficios de Pandas encontramos, facilidad de uso, manejo de datos faltantes, analisis eficientes y obviamente su impacto en el almacenamiento de Datos en DataLakes.\n",
    "\n",
    "Impacto de Pandas en el manejo de DataLakes:\n",
    "En la era del BigData los DataLakes se han convertido en una solucion popular para almacenar grandes volumenes de datos en su forma original. Esto permite a las organizaciones conservar datos sin una estructura rigida, lo que resulta útil para el análisis posterior.Aqui es donde Pandas muestra su verdadero valor al facilitar el trabajo en estos entornos:\n",
    "\n",
    "Que es un DataLAke?\n",
    "Un DataLake es un repositorio que permite almacenar datos de diferentes tipos(estructurados, semiestructurados y no estructurados) de manera eficiente y escalable. A diferencia de las bases de datos tradicionales, un DataLake no requiere que los datos sean organizados en tablas antes de su almacenamiento, lo que brinda mayor flexibilidad. Sin embargo, esta felxibilidad tambien puede presentar desafios a la hora de acceder y analizar los datos.\n",
    "\n",
    "Rol de Pandas en DataLakes\n",
    "Limpieza y transformación de Datos:\n",
    "Antes de almacenar en un DL es esencial limpiar y transformar. Pamdas permite a los usuarios eliminar datos erroneos, rellenar valores faltantes y estandarizar formatos. Este proceso garantiza que los datos almacenados sean de alta calidad, lo que es fundamental para analisis futuros.\n",
    "\n",
    "Preparación para el Análisis:\n",
    "Una vez que los datos estan en DL, la preparación para el análisis puede ser complicada si los datos no estan bien organziados. Usando Pandas, los analistas pueden manipular los datos desde el DL y estructurarlos de forma adecuada antes de realizar cualquier análisis. Esto incluye actividades como la agregación de datos, la creación de subconjuntos y la fusion de diferentes conjuntos de datos.\n",
    "\n",
    "Facilitación del acceso a la información:\n",
    "Con los datos adecuadamente organizados y limpios, Pandas facilita el acceso a la información relevante. Esto significa que los analistas pueden ejecutar consultas y generar informes más rápidamente, lo que acelera la toma de decisiones de la organización\n",
    "\n",
    "Optimizacion y rendimiento:\n",
    "Pandas ayuda a reducir el tiempo de procesamiento necesario para analizar datos almacenados en un DL. Al realizar transformaciones y análisis previos a la carga de datos, los usuarios pueden evitar procesos pesados y complejos que ralentizan el acceso a la información.\n",
    "\n",
    "La combinación de Pandas y DataLakes proporciona entornos robustos y eficientes para el manejo de grandes volumenes de datos\n",
    "\n",
    "Fuentes\n",
    "McKinney, W. (2010). Data Analysis in Python. Retrieved from Pandas Documentation.\n",
    "\n",
    "Wes McKinney. (2009). Pandas: A Foundational Library for Data Analysis in Python. Retrieved from Pandas Documentation.\n",
    "\n",
    "McKinney, W. (2020). Pandas 1.0.0 Release Notes. Retrieved from Pandas Documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79053b-1a74-46e9-abd6-cff6c23008b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
